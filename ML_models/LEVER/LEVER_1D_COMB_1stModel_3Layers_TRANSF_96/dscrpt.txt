def build_branched_model1(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(filters=128, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_1_1')(input1)
    # x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_1_2')(x1)
    x1 = Dropout(rate=0.2, name='dropout_1_1')(x1)
    x1 = Conv1D(filters=256, kernel_size=2, strides=1, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='gap1d_1_1')(x1)
    
    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_2_1')(input2)
    # x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    x2 = Dropout(rate=0.2, name='dropout_2_1')(x2)
    x2 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_2_3')(x2)
    x2 = GlobalMaxPooling1D(name='gap1d_2_1')(x2)
    
    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(filters=64, kernel_size=40, strides=10, activation='relu', padding='same', name='conv1d_3_1')(input3)
    # x3 = MaxPooling1D(pool_size=2, name='maxpool1d_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=8, strides=2, activation='relu', name='conv1d_3_2')(x3)
    x3 = Dropout(rate=0.2, name='dropout_3_1')(x3)
    x3 = Conv1D(filters=128, kernel_size=2, strides=1, activation='relu', name='conv1d_3_3')(x3)
    x3 = GlobalMaxPooling1D(name='gap1d_3_1')(x3)
    
    # Concatenate the outputs of the three branches
    merged = concatenate([x1, x2, x3], name='concatenate_1')
    
    # Dense layer
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=[input1, input2, input3], outputs=output)
    return model

Model: "functional"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 2000, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 2000, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 200, 128)  │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 200, 64)   │      5,184 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 200, 64)   │      2,624 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 97, 128)   │    131,200 │ conv1d_1_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 97, 128)   │     65,664 │ conv1d_2_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 97, 128)   │     65,664 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 97, 128)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 97, 128)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 97, 128)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 96, 256)   │     65,792 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 96, 128)   │     32,896 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 96, 128)   │     32,896 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 128)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 128)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 512)       │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     32,832 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 3)         │         51 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 1,338,635 (5.11 MB)
 Trainable params: 446,211 (1.70 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 892,424 (3.40 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f109117a560>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.11271388083696365
Test val_loss: 0.3929416239261627
Train accuracy: 0.9647302627563477
Accuracy Score: 0.9627329192546584
F1 Score: 0.9582657643374614
Classification Report:
               precision    recall  f1-score   support

         0.0       0.97      0.99      0.98        75
         1.0       0.93      0.95      0.94        42
         2.0       0.98      0.93      0.95        44

    accuracy                           0.96       161
   macro avg       0.96      0.96      0.96       161
weighted avg       0.96      0.96      0.96       161

Training History:
accuracy: [0.46680498123168945, 0.5975103974342346, 0.6576763391494751, 0.7634854912757874, 0.6991701126098633, 0.7987551689147949, 0.7531120181083679, 0.8091286420822144, 0.8029045462608337, 0.7800830006599426, 0.8817427158355713, 0.8713693022727966, 0.8962655663490295, 0.9004149436950684, 0.8443983197212219, 0.8983402252197266, 0.9170124530792236, 0.9128630757331848, 0.9253112077713013, 0.9149377346038818, 0.9211618304252625, 0.8921161890029907, 0.9128630757331848, 0.8921161890029907, 0.8962655663490295, 0.9336099624633789, 0.9460580945014954, 0.9481327533721924, 0.9356846213340759, 0.9336099624633789, 0.9709543585777283, 0.9647302627563477, 0.9522821307182312, 0.9377593398094177, 0.9315352439880371, 0.9149377346038818, 0.9170124530792236, 0.9190871119499207, 0.9481327533721924, 0.9626556038856506, 0.9522821307182312, 0.9647302627563477]
loss: [1.012079119682312, 0.8634442687034607, 0.7301710844039917, 0.5871595740318298, 0.6569613218307495, 0.519927442073822, 0.5882886052131653, 0.460534006357193, 0.47019726037979126, 0.5046437978744507, 0.3975153863430023, 0.3561111092567444, 0.32788121700286865, 0.29036667943000793, 0.4051724076271057, 0.29066982865333557, 0.2862980365753174, 0.25274327397346497, 0.2255324423313141, 0.22434382140636444, 0.22080259025096893, 0.2893657386302948, 0.25588303804397583, 0.31059736013412476, 0.2892986536026001, 0.20506687462329865, 0.18269787728786469, 0.16114051640033722, 0.19602647423744202, 0.18253815174102783, 0.11415453255176544, 0.13955968618392944, 0.15519331395626068, 0.18045847117900848, 0.17521779239177704, 0.18457463383674622, 0.22607439756393433, 0.23707038164138794, 0.14300300180912018, 0.11107340455055237, 0.1513715237379074, 0.11271388083696365]
val_accuracy: [0.4906832277774811, 0.5652173757553101, 0.7763975262641907, 0.7080745100975037, 0.8012422323226929, 0.8074533939361572, 0.782608687877655, 0.8757764101028442, 0.695652186870575, 0.8757764101028442, 0.850931704044342, 0.8571428656578064, 0.9192546606063843, 0.850931704044342, 0.9006211161613464, 0.8571428656578064, 0.9006211161613464, 0.95652174949646, 0.9130434989929199, 0.9192546606063843, 0.9503105878829956, 0.9006211161613464, 0.850931704044342, 0.9627329111099243, 0.9316770434379578, 0.9440993666648865, 0.9316770434379578, 0.9006211161613464, 0.95652174949646, 0.9751552939414978, 0.9440993666648865, 0.9192546606063843, 0.9006211161613464, 0.9316770434379578, 0.9316770434379578, 0.8944099545478821, 0.9440993666648865, 0.9440993666648865, 0.95652174949646, 0.95652174949646, 0.9130434989929199, 0.8447204828262329]
val_loss: [0.9109188914299011, 0.7898108959197998, 0.5996776223182678, 0.6748623251914978, 0.5340827703475952, 0.4658757448196411, 0.5074248909950256, 0.3327198028564453, 0.5791564583778381, 0.32051146030426025, 0.3535471558570862, 0.3149034380912781, 0.2554960548877716, 0.3340759873390198, 0.32091355323791504, 0.3741482198238373, 0.2495323121547699, 0.20455427467823029, 0.22496739029884338, 0.2445801943540573, 0.18466484546661377, 0.2690569758415222, 0.3644760847091675, 0.16730396449565887, 0.2025461345911026, 0.19194138050079346, 0.20916520059108734, 0.22938063740730286, 0.15268675982952118, 0.14097756147384644, 0.16855168342590332, 0.2663711607456207, 0.24761898815631866, 0.15000224113464355, 0.15109138190746307, 0.2152005285024643, 0.16503487527370453, 0.17813117802143097, 0.1537090390920639, 0.17103886604309082, 0.18350829184055328, 0.3929416239261627]

Confusion Matrix:
[[74  0  1]
 [ 2 40  0]
 [ 0  3 41]]

################################################################################################ 

