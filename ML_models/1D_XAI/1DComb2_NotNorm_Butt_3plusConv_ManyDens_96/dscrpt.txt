Building Function:
def build_SeparatedEASYmodel(input_shape1, input_shape2, input_shape3):
    # First input branch
    input1 = Input(shape=input_shape1, name='input1')
    x1 = Conv1D(128, kernel_size=40, strides=8, activation='relu', name='conv1d_1_1')(input1)
    x1 = MaxPooling1D(pool_size=2, name='maxpool1d_1_1')(x1)
    x1 = Conv1D(128, kernel_size=20, strides=2, activation='relu', name='conv1d_1_2')(x1)
    x1 = Conv1D(256, kernel_size=4, activation='relu', name='conv1d_1_3')(x1)
    x1 = GlobalMaxPooling1D(name='globalmaxpool1d_1_1')(x1)
    x1 = Dense(128, activation='relu', name='dense_1_1')(x1)
    x1 = Dropout(0.2, name='dropout_1_1')(x1)
    out1 = Dense(64, activation='relu', name='dense_1_2')(x1)

    # Second input branch
    input2 = Input(shape=input_shape2, name='input2')
    x2 = Conv1D(128, kernel_size=2, activation='relu', name='conv1d_2_1')(input2)
    x2 = MaxPooling1D(pool_size=2, name='maxpool1d_2_1')(x2)
    x2 = Conv1D(64, kernel_size=8, strides=2, activation='relu', name='conv1d_2_2')(x2)
    x2 = Conv1D(128, kernel_size=4, activation='relu', name='conv1d_2_3')(x2)
    x2 = Conv1D(64, kernel_size=2, activation='relu', name='conv1d_2_4')(x2)
    x2 = GlobalMaxPooling1D(name='globalmaxpool1d_2_1')(x2)
    x2 = Dropout(0.1, name='dropout_2_1')(x2)
    out2 = Dense(64, activation='relu', name='dense_2_1')(x2)

    # Third input branch
    input3 = Input(shape=input_shape3, name='input3')
    x3 = Conv1D(64, kernel_size=40, strides=10, activation='relu', name='conv1d_3_1')(input3)
    x3 = Conv1D(64, kernel_size=10, activation='relu', name='conv1d_3_2')(x3)
    x3 = GlobalMaxPooling1D(name = 'globalmaxpool1d_3_1')(x3)
    out3 = Dense(32, activation='relu', name='dense_3_1')(x3)

    # Concatenate the outputs of the branches
    merged = concatenate([out1, out2, out3], name='concatenate_1')
    merged = Dropout(0.2, name='dropout_merged')(merged)
    merged = Dense(64, activation='relu', name='dense_merged_1')(merged)
    output = Dense(1, activation='sigmoid', name='output')(merged)

    # Create the model
    separated_model = Model(inputs=[input1, input2, input3], outputs=output)

    return separated_model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 0], data[:, :, 2]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 3],))
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 0]))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 800, 1)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 96, 128)   │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 799, 128)  │        384 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_1_1       │ (None, 48, 128)   │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_2_1       │ (None, 399, 128)  │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 15, 128)   │    327,808 │ maxpool1d_1_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 196, 64)   │     65,600 │ maxpool1d_2_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 12, 256)   │    131,328 │ conv1d_1_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 193, 128)  │     32,896 │ conv1d_2_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 800, 2)    │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_1_1 │ (None, 256)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_4 (Conv1D) │ (None, 192, 64)   │     16,448 │ conv1d_2_3[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 77, 64)    │      5,184 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1_1 (Dense)   │ (None, 128)       │     32,896 │ globalmaxpool1d_… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_2_1 │ (None, 64)        │          0 │ conv1d_2_4[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 68, 64)    │     41,024 │ conv1d_3_1[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 128)       │          0 │ dense_1_1[0][0]   │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 64)        │          0 │ globalmaxpool1d_… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ globalmaxpool1d_3_1 │ (None, 64)        │          0 │ conv1d_3_2[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1_2 (Dense)   │ (None, 64)        │      8,256 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2_1 (Dense)   │ (None, 64)        │      4,160 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_3_1 (Dense)   │ (None, 32)        │      2,080 │ globalmaxpool1d_… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 160)       │          0 │ dense_1_2[0][0],  │
│ (Concatenate)       │                   │            │ dense_2_1[0][0],  │
│                     │                   │            │ dense_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_merged      │ (None, 160)       │          0 │ concatenate_1[0]… │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_merged_1      │ (None, 64)        │     10,304 │ dropout_merged[0… │
│ (Dense)             │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 1)         │         65 │ dense_merged_1[0… │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 2,066,405 (7.88 MB)
 Trainable params: 688,801 (2.63 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 1,377,604 (5.26 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7fcb1015d690>
Loss Function: binary_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.08046963065862656
Test val_loss: 0.23903939127922058
Train accuracy: 0.9681456089019775
Accuracy Score: 0.9556313993174061
F1 Score: 0.9592476489028213
Classification Report:
               precision    recall  f1-score   support

         0.0       0.93      0.98      0.95       130
         1.0       0.98      0.94      0.96       163

    accuracy                           0.96       293
   macro avg       0.95      0.96      0.96       293
weighted avg       0.96      0.96      0.96       293

Training History:
accuracy: [0.6063708662986755, 0.7519909143447876, 0.7906712293624878, 0.7986348271369934, 0.7974971532821655, 0.8077360391616821, 0.7986348271369934, 0.8418657779693604, 0.8464163541793823, 0.8350397944450378, 0.8646188974380493, 0.8464163541793823, 0.8543799519538879, 0.8805460929870605, 0.8794084191322327, 0.8873720169067383, 0.8976109027862549, 0.912400484085083, 0.871444821357727, 0.8907849788665771, 0.914675772190094, 0.9226393699645996, 0.9237770438194275, 0.914675772190094, 0.9283276200294495, 0.9385665655136108, 0.9180887341499329, 0.935153603553772, 0.9499431252479553, 0.9510807991027832, 0.9488054513931274, 0.9442548155784607, 0.9556313753128052, 0.9647326469421387, 0.9590443968772888, 0.9567690491676331, 0.9624573588371277, 0.9419795274734497, 0.9408418536186218, 0.9579067230224609, 0.9715585708618164, 0.9601820111274719, 0.9556313753128052, 0.9749715328216553, 0.9726962447166443, 0.9852104783058167, 0.9738339185714722, 0.9852104783058167, 0.9715585708618164, 0.9681456089019775]
loss: [0.652891218662262, 0.5346968173980713, 0.4523915946483612, 0.43448472023010254, 0.4200952649116516, 0.4039623737335205, 0.4129543900489807, 0.3564474582672119, 0.345306396484375, 0.34537872672080994, 0.32483500242233276, 0.33904924988746643, 0.32107216119766235, 0.29781782627105713, 0.26769083738327026, 0.2565021812915802, 0.2443646788597107, 0.21858182549476624, 0.28978651762008667, 0.2462122142314911, 0.20770740509033203, 0.18817180395126343, 0.1883566677570343, 0.18770061433315277, 0.1880921572446823, 0.15616124868392944, 0.18278206884860992, 0.17991892993450165, 0.13111752271652222, 0.13312560319900513, 0.1265694797039032, 0.13751885294914246, 0.12682203948497772, 0.10561297088861465, 0.110230952501297, 0.11206437647342682, 0.09590696543455124, 0.1280684769153595, 0.14330895245075226, 0.10881393402814865, 0.07590232789516449, 0.11265242844820023, 0.0975240021944046, 0.06517156958580017, 0.07678664475679398, 0.04691297933459282, 0.07626660168170929, 0.04492506757378578, 0.07781123369932175, 0.08046963065862656]
val_accuracy: [0.7952218651771545, 0.80887371301651, 0.80887371301651, 0.8156996369361877, 0.8327645063400269, 0.8430033922195435, 0.829351544380188, 0.849829375743866, 0.829351544380188, 0.8532423377037048, 0.849829375743866, 0.849829375743866, 0.8532423377037048, 0.894197940826416, 0.873720109462738, 0.8805460929870605, 0.8839590549468994, 0.9010238647460938, 0.8634812235832214, 0.894197940826416, 0.9112628102302551, 0.914675772190094, 0.873720109462738, 0.9044368863105774, 0.9010238647460938, 0.8976109027862549, 0.8907849788665771, 0.9010238647460938, 0.9078498482704163, 0.9215016961097717, 0.914675772190094, 0.9078498482704163, 0.9112628102302551, 0.9180887341499329, 0.9180887341499329, 0.9180887341499329, 0.9180887341499329, 0.9283276200294495, 0.9249146580696106, 0.9317406415939331, 0.935153603553772, 0.935153603553772, 0.9283276200294495, 0.9283276200294495, 0.914675772190094, 0.9419795274734497, 0.9317406415939331, 0.9385665655136108, 0.9385665655136108, 0.935153603553772]
val_loss: [0.49668359756469727, 0.44385823607444763, 0.4293397068977356, 0.42086896300315857, 0.3579390347003937, 0.3774722218513489, 0.3377746641635895, 0.32986554503440857, 0.336651474237442, 0.2956571578979492, 0.3370938003063202, 0.3269350528717041, 0.3707400858402252, 0.2533109188079834, 0.2782454490661621, 0.27809035778045654, 0.26511356234550476, 0.23670624196529388, 0.30453166365623474, 0.2572735846042633, 0.2216237485408783, 0.23209169507026672, 0.3035764992237091, 0.23327870666980743, 0.24289479851722717, 0.32237088680267334, 0.2575737535953522, 0.22771362960338593, 0.2561807930469513, 0.2098412811756134, 0.208128422498703, 0.2895435094833374, 0.2537115216255188, 0.2686220109462738, 0.21981212496757507, 0.2310037761926651, 0.26547524333000183, 0.21373939514160156, 0.21931423246860504, 0.1961810141801834, 0.23009811341762543, 0.19965943694114685, 0.23141083121299744, 0.21116286516189575, 0.26755058765411377, 0.23818077147006989, 0.24291960895061493, 0.24690786004066467, 0.20623156428337097, 0.23903939127922058]

Confusion Matrix:
[[127   3]
 [ 10 153]]

################################################################################################ 

