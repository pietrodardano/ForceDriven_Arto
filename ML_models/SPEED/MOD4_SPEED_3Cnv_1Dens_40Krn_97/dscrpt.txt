Building Function:
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=64*FILTN, kernel_size=40, strides=10, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = MaxPooling1D(pool_size=2)(x)
        x = Conv1D(filters=128*FILTN, kernel_size=8, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        x = Dropout(rate=0.2, name=f'dropout_{branch_id}_1')(x)
        x = Conv1D(filters=256*FILTN, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    #dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = data[:, :, 1]
        globals()[f"{key}2"] = data[:, :, 5]
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 4]))
        globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_3"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input4 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 180, 128)  │      5,248 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 180, 128)  │      5,248 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 180, 128)  │     10,368 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_1 (Conv1D) │ (None, 180, 128)  │     10,368 │ input4[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_8     │ (None, 90, 128)   │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_9     │ (None, 90, 128)   │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_10    │ (None, 90, 128)   │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_11    │ (None, 90, 128)   │          0 │ conv1d_4_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 42, 256)   │    262,400 │ max_pooling1d_8[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 42, 256)   │    262,400 │ max_pooling1d_9[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 42, 256)   │    262,400 │ max_pooling1d_10… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_2 (Conv1D) │ (None, 42, 256)   │    262,400 │ max_pooling1d_11… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_1_1         │ (None, 42, 256)   │          0 │ conv1d_1_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_2_1         │ (None, 42, 256)   │          0 │ conv1d_2_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_3_1         │ (None, 42, 256)   │          0 │ conv1d_3_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dropout_4_1         │ (None, 42, 256)   │          0 │ conv1d_4_2[0][0]  │
│ (Dropout)           │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 41, 512)   │    262,656 │ dropout_1_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 41, 512)   │    262,656 │ dropout_2_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 41, 512)   │    262,656 │ dropout_3_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_3 (Conv1D) │ (None, 41, 512)   │    262,656 │ dropout_4_1[0][0] │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 512)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 512)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 512)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_4_1           │ (None, 512)       │          0 │ conv1d_4_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 2048)      │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0],  │
│                     │                   │            │ gap1d_4_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │    131,136 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 4)         │        260 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 6,788,558 (25.90 MB)
 Trainable params: 2,262,852 (8.63 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 4,525,706 (17.26 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f5e749a97e0>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.22081874310970306
Test val_loss: 0.17258836328983307
Train accuracy: 0.9139785170555115
Accuracy Score: 0.967741935483871
F1 Score: 0.9637722829212191
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      1.00      1.00        29
         1.0       1.00      1.00      1.00        22
         2.0       0.88      1.00      0.94        22
         3.0       1.00      0.85      0.92        20

    accuracy                           0.97        93
   macro avg       0.97      0.96      0.96        93
weighted avg       0.97      0.97      0.97        93

Training History:
accuracy: [0.29749104380607605, 0.49462366104125977, 0.5663082599639893, 0.7168458700180054, 0.7992831468582153, 0.759856641292572, 0.7562723755836487, 0.8028674125671387, 0.8028674125671387, 0.8458781242370605, 0.856630802154541, 0.8494623899459839, 0.8637992739677429, 0.8996415734291077, 0.8924731016159058, 0.9103942513465881, 0.8745519518852234, 0.9032257795333862, 0.9068100452423096, 0.8853046298027039, 0.9211469292640686, 0.91756272315979, 0.9139785170555115, 0.9068100452423096, 0.9103942513465881, 0.91756272315979, 0.9247311949729919, 0.9103942513465881, 0.9426523447036743, 0.9534050226211548, 0.9462365508079529, 0.9462365508079529, 0.9139785170555115]
loss: [1.3920354843139648, 1.1029491424560547, 0.9201202988624573, 0.6824475526809692, 0.5383389592170715, 0.609006404876709, 0.7105898857116699, 0.48644208908081055, 0.4435822367668152, 0.39490148425102234, 0.37067869305610657, 0.30502113699913025, 0.32462748885154724, 0.2520385682582855, 0.2730694115161896, 0.22680889070034027, 0.2524127662181854, 0.19796006381511688, 0.22779405117034912, 0.28098443150520325, 0.2094881385564804, 0.21544134616851807, 0.2156495898962021, 0.21737471222877502, 0.2189793586730957, 0.21343128383159637, 0.18269619345664978, 0.19245736300945282, 0.13928379118442535, 0.1297268122434616, 0.1479245275259018, 0.1297905147075653, 0.22081874310970306]
val_accuracy: [0.5591397881507874, 0.6451612710952759, 0.6236559152603149, 0.7956989407539368, 0.7634408473968506, 0.8279569745063782, 0.8172042965888977, 0.8172042965888977, 0.8064516186714172, 0.9139785170555115, 0.7849462628364563, 0.8817204236984253, 0.8924731016159058, 0.9139785170555115, 0.9247311949729919, 0.9354838728904724, 0.9354838728904724, 0.9247311949729919, 0.8709677457809448, 0.8279569745063782, 0.9247311949729919, 0.8709677457809448, 0.9354838728904724, 0.9462365508079529, 0.9569892287254333, 0.9247311949729919, 0.9247311949729919, 0.9462365508079529, 0.9247311949729919, 0.9247311949729919, 0.9247311949729919, 0.9139785170555115, 0.9354838728904724]
val_loss: [1.196429967880249, 0.8386644124984741, 0.6689306497573853, 0.6411088705062866, 0.4604355990886688, 0.5126369595527649, 0.4171672463417053, 0.4131239950656891, 0.4441942572593689, 0.3079929053783417, 0.3648223578929901, 0.32196244597435, 0.2404802441596985, 0.24067209661006927, 0.20620495080947876, 0.22854085266590118, 0.18810886144638062, 0.2085142284631729, 0.3689230680465698, 0.32965609431266785, 0.24479693174362183, 0.26264628767967224, 0.18481646478176117, 0.1716434359550476, 0.13239207863807678, 0.1681698113679886, 0.1930251568555832, 0.15695074200630188, 0.1492699235677719, 0.19342824816703796, 0.1454261690378189, 0.20770558714866638, 0.17258836328983307]

Confusion Matrix:
[[29  0  0  0]
 [ 0 22  0  0]
 [ 0  0 22  0]
 [ 0  0  3 17]]

################################################################################################ 

