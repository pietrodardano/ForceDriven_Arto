Building Function:
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=64*FILTN, kernel_size=40, strides=10, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = MaxPooling1D(pool_size=2, strides=2, padding='same', name=f'maxpool1d_{branch_id}_1')(x)
        x = Conv1D(filters=128*FILTN, kernel_size=4, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        # x = Dropout(rate=0.2, name=f'dropout_{branch_id}_1')(x)
        x = Conv1D(filters=256*FILTN, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    #dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = np.dstack((data[:, :, 6], data[:, :, 8]))
        globals()[f"{key}2"] = np.dstack((data[:, :, 1], data[:, :, 5]))
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 4]))
        # Uncomment and modify the line below if you need the fourth set
        # globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_2"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 180, 128)  │     10,368 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 180, 128)  │     10,368 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 180, 128)  │     10,368 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_1_1       │ (None, 90, 128)   │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_2_1       │ (None, 90, 128)   │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ maxpool1d_3_1       │ (None, 90, 128)   │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 44, 256)   │    131,328 │ maxpool1d_1_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 44, 256)   │    131,328 │ maxpool1d_2_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 44, 256)   │    131,328 │ maxpool1d_3_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 43, 512)   │    262,656 │ conv1d_1_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 43, 512)   │    262,656 │ conv1d_2_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 43, 512)   │    262,656 │ conv1d_3_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 512)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 512)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 512)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 1536)      │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │     98,368 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 4)         │        260 │ dense_1[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 3,935,054 (15.01 MB)
 Trainable params: 1,311,684 (5.00 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 2,623,370 (10.01 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f1d946276a0>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.13775715231895447
Test val_loss: 0.30072876811027527
Train accuracy: 0.9426523447036743
Accuracy Score: 0.967741935483871
F1 Score: 0.9680546756766268
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.93      0.96        29
         1.0       0.96      1.00      0.98        22
         2.0       0.95      0.95      0.95        22
         3.0       0.95      1.00      0.98        20

    accuracy                           0.97        93
   macro avg       0.97      0.97      0.97        93
weighted avg       0.97      0.97      0.97        93

Training History:
accuracy: [0.4265232980251312, 0.6451612710952759, 0.774193525314331, 0.781361997127533, 0.7849462628364563, 0.8673835396766663, 0.8530465960502625, 0.8673835396766663, 0.8709677457809448, 0.8387096524238586, 0.8673835396766663, 0.8996415734291077, 0.8996415734291077, 0.8960573673248291, 0.8924731016159058, 0.9354838728904724, 0.9569892287254333, 0.9498208165168762, 0.9498208165168762, 0.9354838728904724, 0.9283154010772705, 0.9498208165168762, 0.9749103784561157, 0.9426523447036743, 0.9569892287254333, 0.9426523447036743]
loss: [1.2205848693847656, 0.866277277469635, 0.5854137539863586, 0.5165130496025085, 0.4437828063964844, 0.29896363615989685, 0.30099043250083923, 0.3372647762298584, 0.2819350063800812, 0.31311559677124023, 0.35941264033317566, 0.2518838346004486, 0.21257857978343964, 0.2531820833683014, 0.2274511307477951, 0.1538802981376648, 0.1323215216398239, 0.1412416249513626, 0.13456910848617554, 0.16123345494270325, 0.15945203602313995, 0.10913844406604767, 0.08976985514163971, 0.10364877432584763, 0.09862174093723297, 0.13775715231895447]
val_accuracy: [0.5376344323158264, 0.774193525314331, 0.774193525314331, 0.7419354915618896, 0.7956989407539368, 0.8924731016159058, 0.8494623899459839, 0.8602150678634644, 0.8494623899459839, 0.8924731016159058, 0.8924731016159058, 0.9247311949729919, 0.8602150678634644, 0.8387096524238586, 0.9139785170555115, 0.8817204236984253, 0.8817204236984253, 0.9247311949729919, 0.9032257795333862, 0.8817204236984253, 0.9032257795333862, 0.8924731016159058, 0.8817204236984253, 0.8924731016159058, 0.9032257795333862, 0.8924731016159058]
val_loss: [1.0208117961883545, 0.596296489238739, 0.5811634659767151, 0.5599161982536316, 0.45222628116607666, 0.3538180887699127, 0.4706355333328247, 0.3537714183330536, 0.3541559875011444, 0.29830077290534973, 0.35867661237716675, 0.27098149061203003, 0.4170188009738922, 0.4669926166534424, 0.24943600594997406, 0.30272674560546875, 0.2632177472114563, 0.24472977221012115, 0.2581323981285095, 0.3089483380317688, 0.3041706085205078, 0.29263004660606384, 0.3447209298610687, 0.3317576050758362, 0.3151933550834656, 0.30072876811027527]

Confusion Matrix:
[[27  1  1  0]
 [ 0 22  0  0]
 [ 0  0 21  1]
 [ 0  0  0 20]]

################################################################################################ 

