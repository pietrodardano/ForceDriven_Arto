Building Function:
def build_branched_model(input_shapes):
    def create_branch(input_shape, branch_id):
        input_layer = Input(shape=input_shape, name=f'input{branch_id}')
        x = Conv1D(filters=64*FILTN, kernel_size=10, strides=2, activation='relu', padding='same', name=f'conv1d_{branch_id}_1')(input_layer)
        x = MaxPooling1D(pool_size=2)(x)
        x = Conv1D(filters=128*FILTN, kernel_size=4, strides=2, activation='relu', name=f'conv1d_{branch_id}_2')(x)
        #x = Dropout(rate=0.2, name=f'dropout_{branch_id}_1')(x)
        x = Conv1D(filters=256*FILTN, kernel_size=2, strides=1, activation='relu', name=f'conv1d_{branch_id}_3')(x)
        x = GlobalMaxPooling1D(name=f'gap1d_{branch_id}_1')(x)
        return input_layer, x

    inputs = []
    branches = []
    
    for i, input_shape in enumerate(input_shapes, 1):
        input_layer, branch_output = create_branch(input_shape, i)
        inputs.append(input_layer)
        branches.append(branch_output)
    
    merged = concatenate(branches, name='concatenate_1')
    
    # Dense layers
    dense = Dense(64, activation='relu', name='dense_1')(merged)
    dense = Dense(16, activation='relu', name='dense_2')(dense)
    
    # Output layer for 6-class classification
    output = Dense(OUT_N, activation='softmax', name='output')(dense)
    
    model = Model(inputs=inputs, outputs=output)
    return model


Assign and Deploy Variables Function:
def assign_and_deploy_variables(data_dict):
    for key, data in data_dict.items():
        globals()[f"{key}1"] = data[:, :, 1]
        globals()[f"{key}2"] = data[:, :, 5]
        globals()[f"{key}3"] = np.dstack((data[:, :, 2], data[:, :, 4]))
        globals()[f"{key}4"] = np.dstack((data[:, :, 6], data[:, :, 8]))


Model: "functional_15"
┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓
┃ Layer (type)        ┃ Output Shape      ┃    Param # ┃ Connected to      ┃
┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩
│ input1 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input2 (InputLayer) │ (None, 1800, 1)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input3 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ input4 (InputLayer) │ (None, 1800, 2)   │          0 │ -                 │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_1 (Conv1D) │ (None, 900, 128)  │      1,408 │ input1[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_1 (Conv1D) │ (None, 900, 128)  │      1,408 │ input2[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_1 (Conv1D) │ (None, 900, 128)  │      2,688 │ input3[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_1 (Conv1D) │ (None, 900, 128)  │      2,688 │ input4[0][0]      │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_8     │ (None, 450, 128)  │          0 │ conv1d_1_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_9     │ (None, 450, 128)  │          0 │ conv1d_2_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_10    │ (None, 450, 128)  │          0 │ conv1d_3_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ max_pooling1d_11    │ (None, 450, 128)  │          0 │ conv1d_4_1[0][0]  │
│ (MaxPooling1D)      │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_2 (Conv1D) │ (None, 224, 256)  │    131,328 │ max_pooling1d_8[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_2 (Conv1D) │ (None, 224, 256)  │    131,328 │ max_pooling1d_9[… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_2 (Conv1D) │ (None, 224, 256)  │    131,328 │ max_pooling1d_10… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_2 (Conv1D) │ (None, 224, 256)  │    131,328 │ max_pooling1d_11… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_1_3 (Conv1D) │ (None, 223, 512)  │    262,656 │ conv1d_1_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_2_3 (Conv1D) │ (None, 223, 512)  │    262,656 │ conv1d_2_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_3_3 (Conv1D) │ (None, 223, 512)  │    262,656 │ conv1d_3_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ conv1d_4_3 (Conv1D) │ (None, 223, 512)  │    262,656 │ conv1d_4_2[0][0]  │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_1_1           │ (None, 512)       │          0 │ conv1d_1_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_2_1           │ (None, 512)       │          0 │ conv1d_2_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_3_1           │ (None, 512)       │          0 │ conv1d_3_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ gap1d_4_1           │ (None, 512)       │          0 │ conv1d_4_3[0][0]  │
│ (GlobalMaxPooling1… │                   │            │                   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ concatenate_1       │ (None, 2048)      │          0 │ gap1d_1_1[0][0],  │
│ (Concatenate)       │                   │            │ gap1d_2_1[0][0],  │
│                     │                   │            │ gap1d_3_1[0][0],  │
│                     │                   │            │ gap1d_4_1[0][0]   │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_1 (Dense)     │ (None, 64)        │    131,136 │ concatenate_1[0]… │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ dense_2 (Dense)     │ (None, 16)        │      1,040 │ dense_1[0][0]     │
├─────────────────────┼───────────────────┼────────────┼───────────────────┤
│ output (Dense)      │ (None, 4)         │         68 │ dense_2[0][0]     │
└─────────────────────┴───────────────────┴────────────┴───────────────────┘
 Total params: 5,149,118 (19.64 MB)
 Trainable params: 1,716,372 (6.55 MB)
 Non-trainable params: 0 (0.00 B)
 Optimizer params: 3,432,746 (13.09 MB)

Model Configuration:
Optimizer: <keras.src.optimizers.adam.Adam object at 0x7f4a5070bd30>
Loss Function: sparse_categorical_crossentropy
Learning Rate: <KerasVariable shape=(), dtype=float32, path=adam/learning_rate>

Train loss: 0.1805478036403656
Test val_loss: 0.7029178738594055
Train accuracy: 0.9247311949729919
Accuracy Score: 0.946236559139785
F1 Score: 0.9473729543496985
Classification Report:
               precision    recall  f1-score   support

         0.0       1.00      0.86      0.93        29
         1.0       1.00      1.00      1.00        22
         2.0       0.91      0.95      0.93        22
         3.0       0.87      1.00      0.93        20

    accuracy                           0.95        93
   macro avg       0.95      0.95      0.95        93
weighted avg       0.95      0.95      0.95        93

Training History:
accuracy: [0.379928320646286, 0.4910394251346588, 0.4695340394973755, 0.5985662937164307, 0.6881720423698425, 0.7670251131057739, 0.7706093192100525, 0.8243727684020996, 0.8315412402153015, 0.8494623899459839, 0.856630802154541, 0.8530465960502625, 0.8745519518852234, 0.8996415734291077, 0.9032257795333862, 0.9068100452423096, 0.9103942513465881, 0.8924731016159058, 0.9211469292640686, 0.9032257795333862, 0.8996415734291077, 0.9211469292640686, 0.9247311949729919, 0.9426523447036743, 0.9426523447036743, 0.8996415734291077, 0.9103942513465881, 0.9283154010772705, 0.9068100452423096, 0.939068078994751, 0.9462365508079529, 0.9318996667861938, 0.9318996667861938, 0.9462365508079529, 0.9247311949729919, 0.9569892287254333, 0.9713261723518372, 0.9462365508079529, 0.9498208165168762, 0.9211469292640686, 0.9247311949729919, 0.9498208165168762, 0.9247311949729919]
loss: [1.343977689743042, 1.1467742919921875, 0.971590518951416, 0.828046977519989, 0.7051875591278076, 0.6468313336372375, 0.5728004574775696, 0.45253172516822815, 0.4067973792552948, 0.4291139245033264, 0.3441525995731354, 0.33428093791007996, 0.30212509632110596, 0.2573363184928894, 0.22107979655265808, 0.1999303549528122, 0.21475140750408173, 0.25665056705474854, 0.22153814136981964, 0.2581219971179962, 0.22333532571792603, 0.19912999868392944, 0.16455136239528656, 0.13780182600021362, 0.16499032080173492, 0.23003096878528595, 0.23023945093154907, 0.18272864818572998, 0.1841576248407364, 0.146996408700943, 0.1448477953672409, 0.15034742653369904, 0.17292281985282898, 0.13975940644741058, 0.1572359800338745, 0.12134437263011932, 0.10937455296516418, 0.15004371106624603, 0.12870146334171295, 0.20088361203670502, 0.1717338263988495, 0.1412707418203354, 0.1805478036403656]
val_accuracy: [0.4301075339317322, 0.5053763389587402, 0.6236559152603149, 0.7204301357269287, 0.7096773982048035, 0.8064516186714172, 0.8709677457809448, 0.774193525314331, 0.7526881694793701, 0.8387096524238586, 0.8602150678634644, 0.8709677457809448, 0.8064516186714172, 0.8494623899459839, 0.8279569745063782, 0.8279569745063782, 0.8602150678634644, 0.8602150678634644, 0.7849462628364563, 0.8709677457809448, 0.8709677457809448, 0.8494623899459839, 0.8924731016159058, 0.8709677457809448, 0.9247311949729919, 0.8924731016159058, 0.8709677457809448, 0.774193525314331, 0.8387096524238586, 0.8924731016159058, 0.8817204236984253, 0.8817204236984253, 0.8709677457809448, 0.9032257795333862, 0.9139785170555115, 0.8924731016159058, 0.9247311949729919, 0.8709677457809448, 0.9139785170555115, 0.8494623899459839, 0.9247311949729919, 0.9032257795333862, 0.8064516186714172]
val_loss: [1.2035859823226929, 0.96613609790802, 0.8365668654441833, 0.677033543586731, 0.6560251116752625, 0.5895106196403503, 0.558064341545105, 0.5843263268470764, 0.661172091960907, 0.4728732407093048, 0.3851545453071594, 0.40134963393211365, 0.4438718557357788, 0.3652499318122864, 0.4251100420951843, 0.4001657962799072, 0.3575891852378845, 0.338458776473999, 0.5287479162216187, 0.39632317423820496, 0.4216025471687317, 0.4194492995738983, 0.37058138847351074, 0.4835397005081177, 0.3224080204963684, 0.273991197347641, 0.4754428565502167, 0.7056443691253662, 0.427595317363739, 0.3027915060520172, 0.4139944612979889, 0.4867732524871826, 0.2502012550830841, 0.35619378089904785, 0.24807831645011902, 0.3487737774848938, 0.36793193221092224, 0.38149312138557434, 0.42817753553390503, 0.6277252435684204, 0.35854265093803406, 0.5133054256439209, 0.7029178738594055]

Confusion Matrix:
[[25  0  2  2]
 [ 0 22  0  0]
 [ 0  0 21  1]
 [ 0  0  0 20]]

################################################################################################ 

